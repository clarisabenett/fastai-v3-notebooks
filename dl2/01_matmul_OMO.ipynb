{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c fastai fastai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c pytorch pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_00 import *\n",
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b): test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/clarisa/.fastai/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.download_data(MNIST_URL, ext='.gz'); path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([50000, 784]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " torch.Size([50000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maps the pytorch tensor function against each\n",
    "# of the loaded arrays to make pytorch versions of them\n",
    "x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "# store the number of \n",
    "# n = rows\n",
    "# c = columns\n",
    "n,c = x_train.shape\n",
    "\n",
    "# take a look at the values and the shapes\n",
    "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.view((28,28)).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 50000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 50000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.t().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 50000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(10,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y =weights.shape;\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mult(w,x):\n",
    "    wr, wc = w.shape\n",
    "    xr, xc = x.shape\n",
    "\n",
    "    assert wc == xr\n",
    "    out = torch.zeros(wr,xc)\n",
    "    \n",
    "    for i in range(wr):\n",
    "        for j in range(xc):\n",
    "            for k in range(wc):\n",
    "                out[i,j] += w[i,k] * x[k,j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 784]), torch.Size([784, 7]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1 = x_train[:,0:7]\n",
    "w1 = weights\n",
    "w1.shape, inp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 958 ms, sys: 1.9 ms, total: 960 ms\n",
      "Wall time: 964 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1 = mat_mult(w1,inp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mult(w,x):\n",
    "    wr, wc = w.shape\n",
    "    xr, xc = x.shape\n",
    "\n",
    "    assert wc == xr\n",
    "    out = torch.zeros(wr,xc)\n",
    "    \n",
    "    for i in range(wr):\n",
    "        for j in range(xc):\n",
    "            out[i,j] = (w[i] * x[:,j]).sum()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 ms ± 124 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _= mat_mult(w1,inp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1[0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1[0].unsqueeze(-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/clarisa/Documents/fast_ai/course-v3-master/nbs/dl2'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(cwd + \"/images/\" + \"dude_wtf_1.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mult(w,x):\n",
    "    wr, wc = w.shape\n",
    "    xr, xc = x.shape\n",
    "\n",
    "    assert wc == xr\n",
    "    out = torch.zeros(wr,xc)\n",
    "    \n",
    "    for i in range(wr):\n",
    "        out[i] = (w[i].unsqueeze(-1) * x).sum(dim=0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(10.0).reshape(2,5)\n",
    "B =A.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_mult(B,A) - B@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 5.],\n",
       "        [1., 6.],\n",
       "        [2., 7.],\n",
       "        [3., 8.],\n",
       "        [4., 9.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[:, 0].expand_as(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  7., 18., 33., 52.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B[:, 0] * A.unsqueeze(1)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6., 7., 8., 9.],\n",
       "        [5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[:, 1].expand_as(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 25.,  42.,  63.,  88., 117.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B[:, 1] * A.unsqueeze(1)).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 30.,  80.],\n",
       "        [ 80., 255.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25., 30., 35., 40., 45.],\n",
       "        [30., 37., 44., 51., 58.],\n",
       "        [35., 44., 53., 62., 71.],\n",
       "        [40., 51., 62., 73., 84.],\n",
       "        [45., 58., 71., 84., 97.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B@A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 649 µs, sys: 430 µs, total: 1.08 ms\n",
      "Wall time: 661 µs\n"
     ]
    }
   ],
   "source": [
    "%time t3 = mat_mult(w1,inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "def test_near(a,b): test(a,b,near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = inp1.t()@w1.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 10]), torch.Size([10, 7]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.shape,t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t3, j.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we try einsum.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mult(w,x): return torch.einsum(\"ik,kj->ij\",w,x).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 27.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "203 µs ± 375 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _= mat_mult(w1,inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(j,mat_mult(w1,inp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_matmul_OMO.ipynb to exp/nb_01.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 01_matmul_OMO.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
